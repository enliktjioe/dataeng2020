{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent_kafka\n",
      "  Downloading confluent_kafka-1.5.0-cp38-cp38-manylinux1_x86_64.whl (8.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting avro\n",
      "  Downloading avro-1.10.0.tar.gz (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 397 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: avro\n",
      "  Building wheel for avro (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro: filename=avro-1.10.0-py3-none-any.whl size=96740 sha256=8aad8de239de37aeba73da6301731281701aed2ed93f64cdff7238ce4a50e456\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e6/b6/4c/5fdfc1ad8cdc72eaca148e328fed1f19a9e67ac7303e1546c7\n",
      "Successfully built avro\n",
      "Installing collected packages: avro\n",
      "Successfully installed avro-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': \"kafka1:9092\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Producer(**conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delivery Call-Back \n",
    "Optional per-message delivery callback (triggered by poll() or flush()) when a message has been successfully delivered or permanently\n",
    "failed delivery (after retries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_callback(err, msg):\n",
    "        if err:\n",
    "            sys.stderr.write('%% Message failed delivery: %s\\n' % err)\n",
    "        else:\n",
    "            sys.stderr.write('%% Message delivered to %s [%d] @ %d\\n' %\n",
    "                             (msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\"ciao ciao ciao\", \"a b c\", \"hey hey hey\"]\n",
    "topic = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciao ciao ciao\n",
      "a b c\n",
      "hey hey hey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b79be27ed7b6>:5: DeprecationWarning: PY_SSIZE_T_CLEAN will be required for '#' formats\n",
      "  p.produce(topic, line.rstrip(), callback=delivery_callback)\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    try:\n",
    "        # Produce line (without newline)\n",
    "        print(line)\n",
    "        p.produce(topic, line.rstrip(), callback=delivery_callback)\n",
    "    except BufferError:\n",
    "        sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "Since produce() is an asynchronous API this poll() call\n",
    "will most likely not serve the delivery callback for the\n",
    "last produce()d message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% Message delivered to test [0] @ 0\n",
      "% Message delivered to test [0] @ 1\n",
      "% Message delivered to test [0] @ 2\n",
      "% Message delivered to test [0] @ 3\n",
      "% Message delivered to test [0] @ 4\n",
      "% Message delivered to test [0] @ 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.poll(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% Waiting for 0 deliveries\n"
     ]
    }
   ],
   "source": [
    "sys.stderr.write('%% Waiting for %d deliveries\\n' % len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException\n",
    "import sys\n",
    "import getopt\n",
    "import json\n",
    "import logging\n",
    "from pprint import pformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'bootstrap.servers': \"kafka1:9092\", \n",
    "    'group.id': \"mygroup\", \n",
    "    'session.timeout.ms': 6000,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logger for consumer (logs will be emitted when poll() is called)\n",
    "logger = logging.getLogger('consumer')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(logging.Formatter('%(asctime)-15s %(levelname)-8s %(message)s'))\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " c = Consumer(conf, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_assignment(consumer, partitions):\n",
    "        print('Assignment:', partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribe to topics\n",
    "c.subscribe(topics, on_assign=print_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment: [TopicPartition{topic=test,partition=0,offset=-1001,error=None}]\n",
      "b'ciao ciao ciao'\n",
      "b'a b c'\n",
      "b'hey hey hey'\n",
      "b'ciao ciao ciao'\n",
      "b'a b c'\n",
      "b'hey hey hey'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "% test [0] at offset 0 with key None:\n",
      "% test [0] at offset 1 with key None:\n",
      "% test [0] at offset 2 with key None:\n",
      "% test [0] at offset 3 with key None:\n",
      "% test [0] at offset 4 with key None:\n",
      "% test [0] at offset 5 with key None:\n",
      "% test [0] at offset 6 with key None:\n",
      "% test [0] at offset 7 with key None:\n",
      "% test [0] at offset 8 with key None:\n",
      "% test [0] at offset 9 with key None:\n",
      "% test [0] at offset 10 with key None:\n",
      "% test [0] at offset 11 with key None:\n",
      "% test [0] at offset 12 with key None:\n",
      "% test [0] at offset 13 with key None:\n",
      "% test [0] at offset 14 with key None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Dolor neque velit sed voluptatem etincidunt velit.'\n",
      "b'Dolor ipsum dolor numquam dolorem tempora numquam.'\n",
      "b'Amet non quaerat ut quaerat porro.'\n",
      "b'Numquam tempora tempora voluptatem est amet.'\n",
      "b'Quiquia amet magnam etincidunt sit.'\n",
      "b'Magnam ipsum ut dolorem.'\n",
      "b'Neque sit voluptatem porro.'\n",
      "b'Porro quaerat porro quaerat.'\n",
      "b'Dolor dolore quiquia velit neque.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%% Aborted by user\n"
     ]
    }
   ],
   "source": [
    "# Read messages from Kafka, print to stdout\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        else:\n",
    "            # Proper message\n",
    "            sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' %\n",
    "             (msg.topic(), msg.partition(), msg.offset(), str(msg.key())))\n",
    "            print(msg.value())\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "finally:\n",
    "    # Close down consumer to commit final offsets.\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to copy the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Admin API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions, ConfigResource, ConfigSource\n",
    "from confluent_kafka import KafkaException\n",
    "import sys\n",
    "import threading\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': \"kafka1:9092,kafka2:9093\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdminClient(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = [\"topic4\", \"topic2\", \"topci3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = [NewTopic(topic, num_partitions=3, \n",
    "        replication_factor=1) for topic in topic_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = a.create_topics(new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic topic4 created\n",
      "Failed to create topic topic2: KafkaError{code=TOPIC_ALREADY_EXISTS,val=36,str=\"Topic 'topic2' already exists.\"}\n",
      "Failed to create topic topci3: KafkaError{code=TOPIC_ALREADY_EXISTS,val=36,str=\"Topic 'topci3' already exists.\"}\n"
     ]
    }
   ],
   "source": [
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Topic {} created\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 topics:\n",
      "  \"test\" with 1 partition(s)\n",
      "  \"_schemas\" with 1 partition(s)\n",
      "  \"topic1\" with 4 partition(s)\n",
      "  \"__consumer_offsets\" with 50 partition(s)\n",
      "  \"_confluent-metrics\" with 12 partition(s)\n",
      "  \"__confluent.support.metrics\" with 1 partition(s)\n"
     ]
    }
   ],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "print(\" {} topics:\".format(len(md.topics)))\n",
    "for t in iter(md.topics.values()):\n",
    "    if t.error is not None:\n",
    "        errstr = \": {}\".format(t.error)\n",
    "    else:\n",
    "        errstr = \"\"\n",
    "    print(\"  \\\"{}\\\" with {} partition(s){}\".format(t, len(t.partitions), errstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = a.delete_topics(topic_names, operation_timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic topic4 deleted\n",
      "Topic topic2 deleted\n",
      "Topic topci3 deleted\n"
     ]
    }
   ],
   "source": [
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Topic {} deleted\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to delete topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"topic1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parts = [NewPartitions(topic, int(5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to add partitions to topic topic1: KafkaError{code=INVALID_PARTITIONS,val=37,str=\"Topic already has 5 partitions.\"}\n"
     ]
    }
   ],
   "source": [
    "fs = a.create_partitions(new_parts, validate_only=False)\n",
    "# Wait for operation to finish.\n",
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Additional partitions created for topic {}\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to add partitions to topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 topics:\n",
      "partition 0 leader: 1, replicas: [1], isrs: [1] errstr: \n",
      "partition 1 leader: 2, replicas: [2], isrs: [2] errstr: \n",
      "partition 2 leader: 1, replicas: [1], isrs: [1] errstr: \n",
      "partition 3 leader: 2, replicas: [2], isrs: [2] errstr: \n",
      "partition 4 leader: 1, replicas: [1], isrs: [1] errstr: \n"
     ]
    }
   ],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "print(\" {} topics:\".format(len(md.topics)))\n",
    "for t in iter(md.topics.values()):\n",
    "    if str(t)==topic:\n",
    "        for p in iter(t.partitions.values()):\n",
    "            if p.error is not None:\n",
    "                errstr = \": {}\".format(p.error)\n",
    "            else:\n",
    "                errstr = \"\"\n",
    "            print(\"partition {} leader: {}, replicas: {},\" \n",
    "                  \" isrs: {} errstr: {}\".format(p.id, p.leader, p.replicas, p.isrs, errstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-86-e4032d168f3d>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-e4032d168f3d>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    for res, f in fs.items():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
